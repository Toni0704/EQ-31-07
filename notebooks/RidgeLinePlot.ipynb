{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy import stats\n",
    "from scipy.stats import gaussian_kde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_qfeatures = np.arange(0.05, 1.05, 0.10)\n",
    "all_qfeatures = np.round(all_qfeatures, 2).tolist()\n",
    "\n",
    "required_columns = [\n",
    "    \"metric_score\",\n",
    "]\n",
    "methods = [\n",
    "    'integrated_gradients',\n",
    "    'deeplift',\n",
    "    'deepliftshap',\n",
    "    'gradshap',\n",
    "    'kernelshap',\n",
    "    'shapleyvalue'\n",
    "]\n",
    "\n",
    "\n",
    "df_reaults_all = pd.DataFrame(columns=['corruption', 'syn_10percent'])\n",
    "skewness = []\n",
    "kurtosis = []\n",
    "\n",
    "for k in all_qfeatures:\n",
    "    results_path = f\"interpretability_results/results_k_feature\"\n",
    "    df_tmp = pd.read_csv(\n",
    "        os.path.join(results_path, f\"interpretability_shapleyvalue__{k}/results_interp__top.csv\"),\n",
    "        # os.path.join(results_path, f\"interpretability_shapleyvalue__{k}/results_interp__bottom.csv\"),\n",
    "        index_col=0\n",
    "    )\n",
    "\n",
    "    tmp = df_tmp[required_columns].copy().reset_index(drop=True).rename(columns={'metric_score': 'syn_10percent'})\n",
    "    skewness.append(stats.skew(tmp, bias=True))\n",
    "    kurtosis.append(stats.kurtosis(tmp, bias=True))\n",
    "\n",
    "    df_tmp = tmp\n",
    "    df_tmp['corruption'] = k\n",
    "    df_reaults_all = pd.concat([df_reaults_all, df_tmp], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_qfeatures = np.arange(0.05, 1.05, 0.10)\n",
    "all_qfeatures = np.round(all_qfeatures, 2).tolist()\n",
    "all_qfeatures.append(1.0)\n",
    "all_qfeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_qfeatures = np.arange(0.05, 1.05, 0.10)\n",
    "all_qfeatures = np.round(all_qfeatures, 2).tolist()\n",
    "\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "ax = None\n",
    "\n",
    "required_columns = [\n",
    "    \"metric_score\",\n",
    "]\n",
    "methods = [\n",
    "    'integrated_gradients',\n",
    "    'deeplift',\n",
    "    'deepliftshap',\n",
    "    'gradshap',\n",
    "    'kernelshap',\n",
    "    'shapleyvalue'\n",
    "]\n",
    "method_titles = [\n",
    "    'Integrated Gradients',\n",
    "    'DeepLIFT',\n",
    "    'DeepSHAP',\n",
    "    'GradientSHAP',\n",
    "    'KernelSHAP',\n",
    "    'Shapley Value Sampling'\n",
    "]\n",
    "\n",
    "skewness_top = []\n",
    "kurtosis_top = []\n",
    "\n",
    "for n, method in enumerate(methods):\n",
    "    df_reaults_all = pd.DataFrame(columns=['corruption', 'syn_10percent'])\n",
    "\n",
    "    skewness_synthetic = []\n",
    "    kurtosis_synthetic = []\n",
    "\n",
    "    for k in all_qfeatures:\n",
    "        results_path = f\"interpretability_results/results_k_feature\"\n",
    "        df_tmp = pd.read_csv(\n",
    "            os.path.join(results_path, f\"interpretability_{method}__{k}/results_interp__top.csv\"),\n",
    "            index_col=0\n",
    "        )\n",
    "        tmp = df_tmp[required_columns].copy().reset_index(drop=True).rename(columns={'metric_score': 'syn_10percent'})\n",
    "        skewness_synthetic.append(stats.skew(tmp, bias=True))\n",
    "        kurtosis_synthetic.append(stats.kurtosis(tmp, bias=True))\n",
    "\n",
    "        df_tmp = tmp\n",
    "        df_tmp['corruption'] = k\n",
    "        df_reaults_all = pd.concat([df_reaults_all, df_tmp], axis=0, ignore_index=True)\n",
    "\n",
    "    ax = plt.subplot(2, 3, n + 1, frameon=False, sharey=ax)\n",
    "    for i in range(10):\n",
    "        kq = all_qfeatures[-i-1]\n",
    "        NormalizedScoreDrop = df_reaults_all[df_reaults_all['corruption'] == kq].loc[:, 'syn_10percent'].values\n",
    "        kde = gaussian_kde(NormalizedScoreDrop)\n",
    "        x = np.linspace(min(NormalizedScoreDrop), max(NormalizedScoreDrop), 1000)\n",
    "        # x = np.linspace(-1, 1, 1000)\n",
    "        ax.plot(x, kde.pdf(x) + i, color=\"k\", zorder=i, linewidth=1)\n",
    "        ax.fill_between(x, kde.pdf(x) + i-0.02, i, color=\"#A7C0DE\", zorder=-i-10, alpha=0.5)\n",
    "        \n",
    "    ax.yaxis.set_tick_params(tick1On=False)\n",
    "    ax.set_xlim(-1, 1)\n",
    "    ax.set_ylim(0, 15)\n",
    "    ax.axvline(0.0, ls=\"--\", lw=0.75, color=\"black\", ymax=0.8)\n",
    "    # ax.set_xlabel(\"Normalized score drop\")\n",
    "    ax.set_xlabel(\"$\\\\tilde{\\\\mathcal{S}}(\\\\overline{\\\\mathbf{X}})$\")\n",
    "    # ax.tick_params(axis=\"x\", labelsize=16)\n",
    "    ax.set_title(f\"{method_titles[n]}\", ha='center', x=0.5, y=-0.20)\n",
    "\n",
    "    if n == 0 or n == 3:\n",
    "        ax.yaxis.set_tick_params(labelleft=True)\n",
    "        ax.set_yticks(np.arange(10))\n",
    "        ax.set_yticklabels([all_qfeatures[-i] for i in range(1, 11)])\n",
    "        ax.set_ylabel(\"k-percentile\", ha='center', x=0.5, y=0.33)\n",
    "        for tick in ax.yaxis.get_major_ticks():\n",
    "            tick.label1.set_fontsize(10)\n",
    "            tick.label1.set_verticalalignment(\"center\")\n",
    "    else:\n",
    "        ax.yaxis.set_tick_params(labelleft=False)\n",
    "\n",
    "    skewness_top.append(np.squeeze(skewness_synthetic))\n",
    "    kurtosis_top.append(np.squeeze(kurtosis_synthetic))\n",
    "plt.tight_layout(w_pad=0.4, h_pad=0.2)\n",
    "plt.savefig(os.path.join(\"interpretability_results/visualization_results\", \"k-percentile.pdf\"), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_qfeatures = np.arange(0.05, 1.05, 0.10)\n",
    "all_qfeatures = np.round(all_qfeatures, 2).tolist()\n",
    "nrows = 2\n",
    "ncols = 5\n",
    "fig, ax = plt.subplots(nrows=nrows, ncols=ncols, figsize=(20, 8), dpi=300)\n",
    "for r in range(nrows):\n",
    "    for c in range(ncols):\n",
    "        k = all_qfeatures[r*ncols+c]\n",
    "        pd_path = f\"interpretability_results/results_k_feature/interpretability_deepliftshap__{k}/results_interp__top.csv\"\n",
    "        df_metric = pd.read_csv(pd_path, index_col=0)\n",
    "        sns.histplot(data=df_metric, x='metric_score', hue='class_name', kde=False, \n",
    "                     bins=30, edgecolor=None, shrink=0.9, palette=['#67adb7', '#e3716e'], ax=ax[r][c])\n",
    "        ax[r][c].set_title(f'k={k}')\n",
    "        ax[r][c].set_xlabel('Normalized score drop')\n",
    "        ax[r][c].set_ylabel('Number of samples')\n",
    "        if r == 1 and c == 4:\n",
    "            legend = ax[r][c].get_legend()\n",
    "            # handles = legend.legendHandles\n",
    "            handles = legend.legend_handles\n",
    "            ax[r][c].legend(handles, [r'$\\tau < 60$', r'$\\tau \\geq 60$'], title='Classes', bbox_to_anchor=(1.35, 1.3))\n",
    "        else:\n",
    "            ax[r][c].get_legend().remove()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"interpretability_results/visualization_results/syntheticDisPerClass.png\", dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
