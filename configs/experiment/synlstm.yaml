# @package _global_

# to execute this experiment run:
# python train.py experiment=example

defaults:
  - override /datamodule: ts_datamodule.yaml
  - override /model: bilstm.yaml
  - override /callbacks: default.yaml
  - override /trainer: default.yaml

# all parameters below will be merged with parameters from default configurations set above
# this allows you to overwrite only specified parameters

tags: ["synthetic", "bilstm"]

seed: 1234

trainer:
  min_epochs: 50
  max_epochs: 300
  accelerator: gpu

model:
  optimizer:
    _target_: torch.optim.RAdam
    lr: 0.001
    weight_decay: 0.0
  net:
    cell_array:
    - 64
    - 128
    # - 128
    - 64
    # dropout: 0.0

datamodule:
  # data_dir: ${paths.data_dir}/dataset_synthetic
  # data_dir: ${paths.data_dir}/dataset_synthetic_snr20
  data_dir: ${paths.data_dir}/syn_10percent_snr5
  feature_name: signal
  target_name: target_sum
  # target_name: target
  id_name: noun_id
  train_batch_size: 64
  val_batch_size: 1
